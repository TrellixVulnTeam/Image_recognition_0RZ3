{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:23, 7.28MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rYA5vNbropkjJJmYIs\nUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2QttzI2Bc5gChYPn2Z88\nEd+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+w79fZebGx9PwTK+f\n+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X18MylKzupXec34t/t\n83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNogN3dhMAjPDPuL1K5p\n4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8AAPzTJegBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+te3P84NddfxJuT\nBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3X6R2HXXiTWOT03Fq\n15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvhmadP7qd2jceH4Zmj\no1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr92iLeKFCtzNMrXr2\n28epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrlilR+983545sblXCHI\nZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5izdSc4tBvPRotJYr\n3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWvtdb2DuPf7eB0ltq1\nSpz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjdevZOa6w/j7V+f+1yu\nGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1vz4/jz8ZL41zD3q3e\nYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJl6SMOrnbara5Fp+Z\n58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj6+GZ3cePUrv+9b/5\nVnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0jz/jvvjP42fYWmvj\n2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvHw5PwzHKwSO364z+K\nN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVprrf3oe99Nzb333p3w\nzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7r4Rntq/dTO16+jx+\n9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1lfGZ9tErt+uZ2/Ozf\nvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39z8Iz2ebAH/7q3fDM\new8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJj5+ldj1+/GF45qt/\nkXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKdy+/Hz2Ptw4epXYvl\nLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI7TrfOxeemRzn7vtL\n8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye74ZmP3n8/tesseKMH\ngMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx7\n3Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUaozjL++VprLd5z9Q8m\n3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fItzdyrXzTzjA1t7h5\nLTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUepuck8XoIx7uWKRE4u\nxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+42owiM+kNuXm+ldf\nSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX4Znzb72e2vX8Ua64\nazq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwzuriT2vV8fJiau95b\nC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZabzIJz0ye5u6ptpZr\nlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ49SurUtbqbnd7XhL\n5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr21dTu9Yu5hqh1g7i\nzXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0SLYCn3Vxz4NafvZma\nO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYepXdsn8V2ttXbhbrxp\n85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa+8Gnn4Vnbp4epna9\n0eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/miunOe6eS82NH9wL\nzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m5rZ34mU4Xz13N7Xr\nb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7z7/4P+GZL1zOtZP9\nx/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte04ePU3PnEq1mneU0\ntasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8vroyij9zWmvtK196\nLTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAU\nJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH/cEoPLO9mqd2Tbu5\nudVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq1/G9++GZxTh+vVpr\nbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwze/Db1K6z4I0eAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdcPV\nMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1cw2RrVWce/8lMl/HG\nu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2ujXOH353n3rfG8/g5\nnixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8QnrnaPU3tujjeC8/0\nnzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx6bf4ZxyNNlK7fvPh\nvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fNpsfxXbuLw9Su0eh8\nau5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeA\nwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvWchqe2XjyKLVrfXaS\nmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LNcK9c3AnPnC72U7v6\nm8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDXyre8fDE1d9ri+x49\njbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1hXx7kWte2+vFWvtZa\ne/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXtxx8Fy16ure3x81wD\n44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3Nk7NPXx0FN+1Hm/l\na621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW31YsXdcwO4wUYrbW2\n6MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWKiFYffhKeGSXfZaaj\n8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2LQbx73b34nZq11nw\nRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY\n2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H3jJex7U3zTUHXhnF\nm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bnB6lda2vxlsjPTnPN\ncM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh7jlwFrzRA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbaTJJlJ5fWO+GZ\nP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK11gbr8e+2WuZKS1pi\nbmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj6/34gezPcoUxx8/j\nz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd2M41hv2Lly+EZw6m\n8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K743dHa/PHT1K7zi3l4\nZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4w961fvz33FpriQLR\n1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+/E9vnEvtOp7kPuN8\nHG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+btlp7jxWj56EZ15q\nuefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHldW06OU7tuvHk1PPPy\nndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab8XKP0+R1nq1yc91l\n/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtkWc/6YpCaW82m4ZlH\n67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM111sfhWeme0epXZlW\ns5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xXuba27ir+8zzu5Nra\nTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d1ge5+rrlIt5C11pr\nm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqttXbnRq4M5+PP4gUT\n08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/oJQp0srJvMoMWv86P\nl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrHi8wmybIepTYAwP+X\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhdVtr1vm\n/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySbxi4miujOJxoRW2tt\nM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzNU7umi/h5bCTvjwvn\ncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyzGucakFruONrVzfhn\n/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa611jqJVr7WWuv3441h\ni1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOtuxWe6Sz/cHHrjR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21KY7iBdg\ntNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3P243MTfv50pLjpfx\nuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJss5N8DuTGWmvxwcn4\nOLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD9762Zq1/5JfNfPPnmW\n2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+vI1u7lk16safBVv9\n3OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHOfD5LrVomL3WmvOHG\nKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFLa611e/Hv1VprvcRc\nsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3crttks/hw46cTP8Kx4\noweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACis\ns8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlHN40TWAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb820941668>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x.astype('float32')/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0], image_shape[1], image_shape[2]), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.int32, shape=(None, n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    F_W = tf.Variable(tf.truncated_normal((conv_ksize[0], conv_ksize[1], x_tensor.shape[3].value, conv_num_outputs)))\n",
    "    F_b = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    output = tf.nn.conv2d(x_tensor, F_W, [1, conv_strides[0], conv_strides[1], 1], 'SAME') + F_b\n",
    "    return tf.nn.max_pool(tf.nn.relu(output), [1, pool_ksize[0], pool_ksize[1], 1], [1, pool_strides[0], pool_strides[1], 1], 'SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用全连接层，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.layers.dense(x_tensor, num_outputs, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.layers.dense(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    output1 = conv2d_maxpool(x, 32, (3,3), (1,1), (3,3), (1,1))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    output1 = flatten(output1)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    output1 = tf.nn.dropout(fully_conn(output1, 350), keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(output1, 10)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    val_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('loss: %10.4f' % loss)\n",
    "    print('validation accuracy: %10.4f' % val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss:     2.1789\n",
      "validation accuracy:     0.1870\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss:     2.0280\n",
      "validation accuracy:     0.2504\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss:     2.0451\n",
      "validation accuracy:     0.2570\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss:     2.0118\n",
      "validation accuracy:     0.2436\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss:     1.9704\n",
      "validation accuracy:     0.2738\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss:     1.9394\n",
      "validation accuracy:     0.2706\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss:     1.9267\n",
      "validation accuracy:     0.2738\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss:     1.8711\n",
      "validation accuracy:     0.2798\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss:     1.7593\n",
      "validation accuracy:     0.3058\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss:     1.7354\n",
      "validation accuracy:     0.2902\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss:     1.7696\n",
      "validation accuracy:     0.3010\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss:     1.6501\n",
      "validation accuracy:     0.3164\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss:     1.7793\n",
      "validation accuracy:     0.3346\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss:     1.5821\n",
      "validation accuracy:     0.3026\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss:     1.5165\n",
      "validation accuracy:     0.3468\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss:     1.4953\n",
      "validation accuracy:     0.3630\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss:     1.4271\n",
      "validation accuracy:     0.3804\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss:     1.3155\n",
      "validation accuracy:     0.4040\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss:     1.2069\n",
      "validation accuracy:     0.4358\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss:     1.2086\n",
      "validation accuracy:     0.4468\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss:     1.1339\n",
      "validation accuracy:     0.4742\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss:     1.1710\n",
      "validation accuracy:     0.4734\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss:     1.0845\n",
      "validation accuracy:     0.4918\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss:     1.0463\n",
      "validation accuracy:     0.4914\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss:     1.0284\n",
      "validation accuracy:     0.4984\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss:     1.0009\n",
      "validation accuracy:     0.5108\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss:     0.9196\n",
      "validation accuracy:     0.5152\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss:     0.9210\n",
      "validation accuracy:     0.5206\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss:     0.8944\n",
      "validation accuracy:     0.5230\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss:     0.8784\n",
      "validation accuracy:     0.5138\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss:     0.8575\n",
      "validation accuracy:     0.5274\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss:     0.7450\n",
      "validation accuracy:     0.5220\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss:     0.7064\n",
      "validation accuracy:     0.5306\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss:     0.6800\n",
      "validation accuracy:     0.5270\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss:     0.6193\n",
      "validation accuracy:     0.5208\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss:     0.6902\n",
      "validation accuracy:     0.5338\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss:     0.6067\n",
      "validation accuracy:     0.5262\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss:     0.6722\n",
      "validation accuracy:     0.5240\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss:     0.6401\n",
      "validation accuracy:     0.5152\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss:     0.5537\n",
      "validation accuracy:     0.5110\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss:     0.5085\n",
      "validation accuracy:     0.5306\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss:     0.4738\n",
      "validation accuracy:     0.5248\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss:     0.4664\n",
      "validation accuracy:     0.5200\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss:     0.4670\n",
      "validation accuracy:     0.5100\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss:     0.3855\n",
      "validation accuracy:     0.5130\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss:     0.3798\n",
      "validation accuracy:     0.5288\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss:     0.3619\n",
      "validation accuracy:     0.5294\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss:     0.3763\n",
      "validation accuracy:     0.5312\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss:     0.3633\n",
      "validation accuracy:     0.5286\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss:     0.3501\n",
      "validation accuracy:     0.5240\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss:     0.3170\n",
      "validation accuracy:     0.5232\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss:     0.3192\n",
      "validation accuracy:     0.5146\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss:     0.2893\n",
      "validation accuracy:     0.5214\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss:     0.3113\n",
      "validation accuracy:     0.5242\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss:     0.2752\n",
      "validation accuracy:     0.5258\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss:     0.3353\n",
      "validation accuracy:     0.5208\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss:     0.2974\n",
      "validation accuracy:     0.5202\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss:     0.3153\n",
      "validation accuracy:     0.5288\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss:     0.2432\n",
      "validation accuracy:     0.5320\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss:     0.2455\n",
      "validation accuracy:     0.5288\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss:     0.2615\n",
      "validation accuracy:     0.5216\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss:     0.2810\n",
      "validation accuracy:     0.5174\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss:     0.2333\n",
      "validation accuracy:     0.5232\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss:     0.2721\n",
      "validation accuracy:     0.4942\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss:     0.2712\n",
      "validation accuracy:     0.5130\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss:     0.2494\n",
      "validation accuracy:     0.5110\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss:     0.2260\n",
      "validation accuracy:     0.5154\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss:     0.1664\n",
      "validation accuracy:     0.5158\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss:     0.1855\n",
      "validation accuracy:     0.5174\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss:     0.1386\n",
      "validation accuracy:     0.5114\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss:     0.1700\n",
      "validation accuracy:     0.5134\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss:     0.1541\n",
      "validation accuracy:     0.5194\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss:     0.1314\n",
      "validation accuracy:     0.5256\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss:     0.1422\n",
      "validation accuracy:     0.5282\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss:     0.1586\n",
      "validation accuracy:     0.5144\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss:     0.1185\n",
      "validation accuracy:     0.5226\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss:     0.1631\n",
      "validation accuracy:     0.5156\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss:     0.1610\n",
      "validation accuracy:     0.5148\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss:     0.1482\n",
      "validation accuracy:     0.5146\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss:     0.1464\n",
      "validation accuracy:     0.5294\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss:     0.1394\n",
      "validation accuracy:     0.5194\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss:     0.1454\n",
      "validation accuracy:     0.5194\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss:     0.1403\n",
      "validation accuracy:     0.5148\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss:     0.1339\n",
      "validation accuracy:     0.5190\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss:     0.1156\n",
      "validation accuracy:     0.5304\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss:     0.1173\n",
      "validation accuracy:     0.5298\n",
      "Epoch 87, CIFAR-10 Batch 1:  loss:     0.1129\n",
      "validation accuracy:     0.5252\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss:     0.0966\n",
      "validation accuracy:     0.5320\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss:     0.1083\n",
      "validation accuracy:     0.5320\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss:     0.0912\n",
      "validation accuracy:     0.5180\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss:     0.1556\n",
      "validation accuracy:     0.5220\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss:     0.1172\n",
      "validation accuracy:     0.5202\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss:     0.1455\n",
      "validation accuracy:     0.5260\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss:     0.1094\n",
      "validation accuracy:     0.5132\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss:     0.1272\n",
      "validation accuracy:     0.5210\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss:     0.0924\n",
      "validation accuracy:     0.5260\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss:     0.0915\n",
      "validation accuracy:     0.5178\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss:     0.0806\n",
      "validation accuracy:     0.5230\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss:     0.0654\n",
      "validation accuracy:     0.5240\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss:     0.0766\n",
      "validation accuracy:     0.5130\n",
      "Epoch 101, CIFAR-10 Batch 1:  loss:     0.1053\n",
      "validation accuracy:     0.5190\n",
      "Epoch 102, CIFAR-10 Batch 1:  loss:     0.0778\n",
      "validation accuracy:     0.5138\n",
      "Epoch 103, CIFAR-10 Batch 1:  loss:     0.0884\n",
      "validation accuracy:     0.5192\n",
      "Epoch 104, CIFAR-10 Batch 1:  loss:     0.0838\n",
      "validation accuracy:     0.5212\n",
      "Epoch 105, CIFAR-10 Batch 1:  loss:     0.0854\n",
      "validation accuracy:     0.5218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106, CIFAR-10 Batch 1:  loss:     0.0796\n",
      "validation accuracy:     0.5190\n",
      "Epoch 107, CIFAR-10 Batch 1:  loss:     0.0905\n",
      "validation accuracy:     0.5212\n",
      "Epoch 108, CIFAR-10 Batch 1:  loss:     0.0805\n",
      "validation accuracy:     0.5316\n",
      "Epoch 109, CIFAR-10 Batch 1:  loss:     0.0957\n",
      "validation accuracy:     0.5250\n",
      "Epoch 110, CIFAR-10 Batch 1:  loss:     0.0909\n",
      "validation accuracy:     0.5202\n",
      "Epoch 111, CIFAR-10 Batch 1:  loss:     0.0786\n",
      "validation accuracy:     0.5178\n",
      "Epoch 112, CIFAR-10 Batch 1:  loss:     0.0809\n",
      "validation accuracy:     0.5280\n",
      "Epoch 113, CIFAR-10 Batch 1:  loss:     0.0743\n",
      "validation accuracy:     0.5212\n",
      "Epoch 114, CIFAR-10 Batch 1:  loss:     0.0886\n",
      "validation accuracy:     0.5176\n",
      "Epoch 115, CIFAR-10 Batch 1:  loss:     0.0644\n",
      "validation accuracy:     0.5142\n",
      "Epoch 116, CIFAR-10 Batch 1:  loss:     0.0703\n",
      "validation accuracy:     0.5182\n",
      "Epoch 117, CIFAR-10 Batch 1:  loss:     0.0913\n",
      "validation accuracy:     0.5214\n",
      "Epoch 118, CIFAR-10 Batch 1:  loss:     0.0818\n",
      "validation accuracy:     0.5214\n",
      "Epoch 119, CIFAR-10 Batch 1:  loss:     0.0841\n",
      "validation accuracy:     0.5186\n",
      "Epoch 120, CIFAR-10 Batch 1:  loss:     0.0887\n",
      "validation accuracy:     0.5202\n",
      "Epoch 121, CIFAR-10 Batch 1:  loss:     0.0663\n",
      "validation accuracy:     0.5214\n",
      "Epoch 122, CIFAR-10 Batch 1:  loss:     0.0711\n",
      "validation accuracy:     0.5238\n",
      "Epoch 123, CIFAR-10 Batch 1:  loss:     0.0563\n",
      "validation accuracy:     0.5218\n",
      "Epoch 124, CIFAR-10 Batch 1:  loss:     0.0669\n",
      "validation accuracy:     0.5210\n",
      "Epoch 125, CIFAR-10 Batch 1:  loss:     0.0575\n",
      "validation accuracy:     0.5266\n",
      "Epoch 126, CIFAR-10 Batch 1:  loss:     0.0905\n",
      "validation accuracy:     0.5158\n",
      "Epoch 127, CIFAR-10 Batch 1:  loss:     0.0756\n",
      "validation accuracy:     0.5218\n",
      "Epoch 128, CIFAR-10 Batch 1:  loss:     0.0800\n",
      "validation accuracy:     0.5152\n",
      "Epoch 129, CIFAR-10 Batch 1:  loss:     0.0793\n",
      "validation accuracy:     0.5114\n",
      "Epoch 130, CIFAR-10 Batch 1:  loss:     0.0680\n",
      "validation accuracy:     0.5126\n",
      "Epoch 131, CIFAR-10 Batch 1:  loss:     0.0710\n",
      "validation accuracy:     0.5142\n",
      "Epoch 132, CIFAR-10 Batch 1:  loss:     0.0780\n",
      "validation accuracy:     0.5244\n",
      "Epoch 133, CIFAR-10 Batch 1:  loss:     0.0759\n",
      "validation accuracy:     0.5150\n",
      "Epoch 134, CIFAR-10 Batch 1:  loss:     0.0797\n",
      "validation accuracy:     0.5186\n",
      "Epoch 135, CIFAR-10 Batch 1:  loss:     0.0796\n",
      "validation accuracy:     0.5226\n",
      "Epoch 136, CIFAR-10 Batch 1:  loss:     0.0675\n",
      "validation accuracy:     0.5148\n",
      "Epoch 137, CIFAR-10 Batch 1:  loss:     0.0678\n",
      "validation accuracy:     0.5268\n",
      "Epoch 138, CIFAR-10 Batch 1:  loss:     0.0749\n",
      "validation accuracy:     0.5244\n",
      "Epoch 139, CIFAR-10 Batch 1:  loss:     0.0762\n",
      "validation accuracy:     0.5178\n",
      "Epoch 140, CIFAR-10 Batch 1:  loss:     0.0858\n",
      "validation accuracy:     0.5104\n",
      "Epoch 141, CIFAR-10 Batch 1:  loss:     0.0577\n",
      "validation accuracy:     0.5170\n",
      "Epoch 142, CIFAR-10 Batch 1:  loss:     0.0599\n",
      "validation accuracy:     0.5198\n",
      "Epoch 143, CIFAR-10 Batch 1:  loss:     0.0545\n",
      "validation accuracy:     0.5116\n",
      "Epoch 144, CIFAR-10 Batch 1:  loss:     0.0743\n",
      "validation accuracy:     0.5200\n",
      "Epoch 145, CIFAR-10 Batch 1:  loss:     0.0694\n",
      "validation accuracy:     0.5288\n",
      "Epoch 146, CIFAR-10 Batch 1:  loss:     0.0789\n",
      "validation accuracy:     0.5226\n",
      "Epoch 147, CIFAR-10 Batch 1:  loss:     0.0766\n",
      "validation accuracy:     0.5258\n",
      "Epoch 148, CIFAR-10 Batch 1:  loss:     0.0830\n",
      "validation accuracy:     0.5044\n",
      "Epoch 149, CIFAR-10 Batch 1:  loss:     0.0835\n",
      "validation accuracy:     0.5212\n",
      "Epoch 150, CIFAR-10 Batch 1:  loss:     0.0807\n",
      "validation accuracy:     0.5180\n",
      "Epoch 151, CIFAR-10 Batch 1:  loss:     0.0717\n",
      "validation accuracy:     0.5140\n",
      "Epoch 152, CIFAR-10 Batch 1:  loss:     0.0654\n",
      "validation accuracy:     0.5304\n",
      "Epoch 153, CIFAR-10 Batch 1:  loss:     0.0678\n",
      "validation accuracy:     0.5224\n",
      "Epoch 154, CIFAR-10 Batch 1:  loss:     0.0719\n",
      "validation accuracy:     0.5210\n",
      "Epoch 155, CIFAR-10 Batch 1:  loss:     0.0706\n",
      "validation accuracy:     0.5124\n",
      "Epoch 156, CIFAR-10 Batch 1:  loss:     0.0622\n",
      "validation accuracy:     0.5136\n",
      "Epoch 157, CIFAR-10 Batch 1:  loss:     0.0662\n",
      "validation accuracy:     0.5072\n",
      "Epoch 158, CIFAR-10 Batch 1:  loss:     0.0751\n",
      "validation accuracy:     0.5168\n",
      "Epoch 159, CIFAR-10 Batch 1:  loss:     0.0660\n",
      "validation accuracy:     0.5212\n",
      "Epoch 160, CIFAR-10 Batch 1:  loss:     0.0784\n",
      "validation accuracy:     0.5150\n",
      "Epoch 161, CIFAR-10 Batch 1:  loss:     0.0673\n",
      "validation accuracy:     0.5198\n",
      "Epoch 162, CIFAR-10 Batch 1:  loss:     0.0591\n",
      "validation accuracy:     0.5080\n",
      "Epoch 163, CIFAR-10 Batch 1:  loss:     0.0746\n",
      "validation accuracy:     0.5178\n",
      "Epoch 164, CIFAR-10 Batch 1:  loss:     0.0609\n",
      "validation accuracy:     0.5174\n",
      "Epoch 165, CIFAR-10 Batch 1:  loss:     0.0590\n",
      "validation accuracy:     0.5204\n",
      "Epoch 166, CIFAR-10 Batch 1:  loss:     0.0716\n",
      "validation accuracy:     0.5120\n",
      "Epoch 167, CIFAR-10 Batch 1:  loss:     0.0623\n",
      "validation accuracy:     0.5186\n",
      "Epoch 168, CIFAR-10 Batch 1:  loss:     0.0639\n",
      "validation accuracy:     0.5200\n",
      "Epoch 169, CIFAR-10 Batch 1:  loss:     0.0562\n",
      "validation accuracy:     0.5092\n",
      "Epoch 170, CIFAR-10 Batch 1:  loss:     0.0588\n",
      "validation accuracy:     0.5206\n",
      "Epoch 171, CIFAR-10 Batch 1:  loss:     0.0718\n",
      "validation accuracy:     0.5128\n",
      "Epoch 172, CIFAR-10 Batch 1:  loss:     0.0601\n",
      "validation accuracy:     0.5186\n",
      "Epoch 173, CIFAR-10 Batch 1:  loss:     0.0730\n",
      "validation accuracy:     0.5120\n",
      "Epoch 174, CIFAR-10 Batch 1:  loss:     0.0635\n",
      "validation accuracy:     0.5130\n",
      "Epoch 175, CIFAR-10 Batch 1:  loss:     0.0667\n",
      "validation accuracy:     0.5162\n",
      "Epoch 176, CIFAR-10 Batch 1:  loss:     0.0622\n",
      "validation accuracy:     0.5128\n",
      "Epoch 177, CIFAR-10 Batch 1:  loss:     0.0609\n",
      "validation accuracy:     0.5122\n",
      "Epoch 178, CIFAR-10 Batch 1:  loss:     0.0644\n",
      "validation accuracy:     0.5076\n",
      "Epoch 179, CIFAR-10 Batch 1:  loss:     0.0614\n",
      "validation accuracy:     0.5068\n",
      "Epoch 180, CIFAR-10 Batch 1:  loss:     0.0844\n",
      "validation accuracy:     0.4952\n",
      "Epoch 181, CIFAR-10 Batch 1:  loss:     0.0640\n",
      "validation accuracy:     0.5118\n",
      "Epoch 182, CIFAR-10 Batch 1:  loss:     0.0669\n",
      "validation accuracy:     0.5066\n",
      "Epoch 183, CIFAR-10 Batch 1:  loss:     0.0601\n",
      "validation accuracy:     0.5058\n",
      "Epoch 184, CIFAR-10 Batch 1:  loss:     0.0579\n",
      "validation accuracy:     0.5114\n",
      "Epoch 185, CIFAR-10 Batch 1:  loss:     0.0580\n",
      "validation accuracy:     0.5042\n",
      "Epoch 186, CIFAR-10 Batch 1:  loss:     0.0600\n",
      "validation accuracy:     0.5090\n",
      "Epoch 187, CIFAR-10 Batch 1:  loss:     0.0613\n",
      "validation accuracy:     0.5064\n",
      "Epoch 188, CIFAR-10 Batch 1:  loss:     0.0911\n",
      "validation accuracy:     0.5080\n",
      "Epoch 189, CIFAR-10 Batch 1:  loss:     0.0714\n",
      "validation accuracy:     0.4982\n",
      "Epoch 190, CIFAR-10 Batch 1:  loss:     0.0535\n",
      "validation accuracy:     0.5048\n",
      "Epoch 191, CIFAR-10 Batch 1:  loss:     0.0693\n",
      "validation accuracy:     0.5038\n",
      "Epoch 192, CIFAR-10 Batch 1:  loss:     0.0577\n",
      "validation accuracy:     0.5122\n",
      "Epoch 193, CIFAR-10 Batch 1:  loss:     0.0628\n",
      "validation accuracy:     0.5014\n",
      "Epoch 194, CIFAR-10 Batch 1:  loss:     0.0574\n",
      "validation accuracy:     0.5116\n",
      "Epoch 195, CIFAR-10 Batch 1:  loss:     0.0658\n",
      "validation accuracy:     0.5090\n",
      "Epoch 196, CIFAR-10 Batch 1:  loss:     0.0593\n",
      "validation accuracy:     0.5212\n",
      "Epoch 197, CIFAR-10 Batch 1:  loss:     0.0665\n",
      "validation accuracy:     0.5136\n",
      "Epoch 198, CIFAR-10 Batch 1:  loss:     0.0643\n",
      "validation accuracy:     0.5038\n",
      "Epoch 199, CIFAR-10 Batch 1:  loss:     0.0505\n",
      "validation accuracy:     0.5034\n",
      "Epoch 200, CIFAR-10 Batch 1:  loss:     0.0626\n",
      "validation accuracy:     0.5058\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss:     2.2069\n",
      "validation accuracy:     0.1990\n",
      "Epoch  1, CIFAR-10 Batch 2:  loss:     2.2401\n",
      "validation accuracy:     0.1722\n",
      "Epoch  1, CIFAR-10 Batch 3:  loss:     2.1554\n",
      "validation accuracy:     0.1778\n",
      "Epoch  1, CIFAR-10 Batch 4:  loss:     2.1484\n",
      "validation accuracy:     0.2028\n",
      "Epoch  1, CIFAR-10 Batch 5:  loss:     2.0143\n",
      "validation accuracy:     0.1640\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss:     2.0189\n",
      "validation accuracy:     0.2484\n",
      "Epoch  2, CIFAR-10 Batch 2:  loss:     2.0346\n",
      "validation accuracy:     0.1968\n",
      "Epoch  2, CIFAR-10 Batch 3:  loss:     1.7879\n",
      "validation accuracy:     0.2678\n",
      "Epoch  2, CIFAR-10 Batch 4:  loss:     1.8454\n",
      "validation accuracy:     0.2688\n",
      "Epoch  2, CIFAR-10 Batch 5:  loss:     1.8486\n",
      "validation accuracy:     0.2580\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss:     1.9452\n",
      "validation accuracy:     0.2290\n",
      "Epoch  3, CIFAR-10 Batch 2:  loss:     1.8383\n",
      "validation accuracy:     0.2726\n",
      "Epoch  3, CIFAR-10 Batch 3:  loss:     1.7097\n",
      "validation accuracy:     0.2802\n",
      "Epoch  3, CIFAR-10 Batch 4:  loss:     1.7607\n",
      "validation accuracy:     0.2764\n",
      "Epoch  3, CIFAR-10 Batch 5:  loss:     1.7069\n",
      "validation accuracy:     0.2758\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss:     1.9361\n",
      "validation accuracy:     0.2638\n",
      "Epoch  4, CIFAR-10 Batch 2:  loss:     1.8311\n",
      "validation accuracy:     0.2700\n",
      "Epoch  4, CIFAR-10 Batch 3:  loss:     1.6618\n",
      "validation accuracy:     0.2860\n",
      "Epoch  4, CIFAR-10 Batch 4:  loss:     1.7400\n",
      "validation accuracy:     0.2762\n",
      "Epoch  4, CIFAR-10 Batch 5:  loss:     1.6797\n",
      "validation accuracy:     0.2690\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss:     1.9275\n",
      "validation accuracy:     0.2586\n",
      "Epoch  5, CIFAR-10 Batch 2:  loss:     1.7687\n",
      "validation accuracy:     0.2936\n",
      "Epoch  5, CIFAR-10 Batch 3:  loss:     1.6447\n",
      "validation accuracy:     0.3104\n",
      "Epoch  5, CIFAR-10 Batch 4:  loss:     1.7548\n",
      "validation accuracy:     0.2918\n",
      "Epoch  5, CIFAR-10 Batch 5:  loss:     1.7232\n",
      "validation accuracy:     0.2576\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss:     1.8847\n",
      "validation accuracy:     0.2714\n",
      "Epoch  6, CIFAR-10 Batch 2:  loss:     1.7222\n",
      "validation accuracy:     0.2800\n",
      "Epoch  6, CIFAR-10 Batch 3:  loss:     1.6186\n",
      "validation accuracy:     0.3004\n",
      "Epoch  6, CIFAR-10 Batch 4:  loss:     1.7309\n",
      "validation accuracy:     0.2890\n",
      "Epoch  6, CIFAR-10 Batch 5:  loss:     1.6370\n",
      "validation accuracy:     0.2732\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss:     1.8412\n",
      "validation accuracy:     0.2650\n",
      "Epoch  7, CIFAR-10 Batch 2:  loss:     1.6986\n",
      "validation accuracy:     0.2962\n",
      "Epoch  7, CIFAR-10 Batch 3:  loss:     1.6066\n",
      "validation accuracy:     0.3042\n",
      "Epoch  7, CIFAR-10 Batch 4:  loss:     1.7461\n",
      "validation accuracy:     0.2972\n",
      "Epoch  7, CIFAR-10 Batch 5:  loss:     1.6043\n",
      "validation accuracy:     0.2844\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss:     1.8237\n",
      "validation accuracy:     0.2684\n",
      "Epoch  8, CIFAR-10 Batch 2:  loss:     1.6739\n",
      "validation accuracy:     0.3158\n",
      "Epoch  8, CIFAR-10 Batch 3:  loss:     1.6114\n",
      "validation accuracy:     0.3016\n",
      "Epoch  8, CIFAR-10 Batch 4:  loss:     1.7231\n",
      "validation accuracy:     0.3002\n",
      "Epoch  8, CIFAR-10 Batch 5:  loss:     1.5481\n",
      "validation accuracy:     0.2974\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss:     1.6766\n",
      "validation accuracy:     0.3278\n",
      "Epoch  9, CIFAR-10 Batch 2:  loss:     1.6769\n",
      "validation accuracy:     0.3208\n",
      "Epoch  9, CIFAR-10 Batch 3:  loss:     1.6374\n",
      "validation accuracy:     0.3262\n",
      "Epoch  9, CIFAR-10 Batch 4:  loss:     1.6841\n",
      "validation accuracy:     0.3518\n",
      "Epoch  9, CIFAR-10 Batch 5:  loss:     1.4531\n",
      "validation accuracy:     0.3402\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss:     1.5921\n",
      "validation accuracy:     0.3492\n",
      "Epoch 10, CIFAR-10 Batch 2:  loss:     1.6379\n",
      "validation accuracy:     0.3454\n",
      "Epoch 10, CIFAR-10 Batch 3:  loss:     1.5666\n",
      "validation accuracy:     0.3408\n",
      "Epoch 10, CIFAR-10 Batch 4:  loss:     1.6111\n",
      "validation accuracy:     0.3596\n",
      "Epoch 10, CIFAR-10 Batch 5:  loss:     1.4134\n",
      "validation accuracy:     0.3702\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss:     1.4875\n",
      "validation accuracy:     0.3716\n",
      "Epoch 11, CIFAR-10 Batch 2:  loss:     1.4662\n",
      "validation accuracy:     0.3960\n",
      "Epoch 11, CIFAR-10 Batch 3:  loss:     1.3755\n",
      "validation accuracy:     0.4150\n",
      "Epoch 11, CIFAR-10 Batch 4:  loss:     1.4782\n",
      "validation accuracy:     0.4370\n",
      "Epoch 11, CIFAR-10 Batch 5:  loss:     1.3097\n",
      "validation accuracy:     0.4314\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss:     1.3345\n",
      "validation accuracy:     0.4554\n",
      "Epoch 12, CIFAR-10 Batch 2:  loss:     1.3678\n",
      "validation accuracy:     0.4606\n",
      "Epoch 12, CIFAR-10 Batch 3:  loss:     1.2769\n",
      "validation accuracy:     0.4608\n",
      "Epoch 12, CIFAR-10 Batch 4:  loss:     1.4350\n",
      "validation accuracy:     0.4690\n",
      "Epoch 12, CIFAR-10 Batch 5:  loss:     1.2762\n",
      "validation accuracy:     0.4696\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss:     1.2682\n",
      "validation accuracy:     0.4830\n",
      "Epoch 13, CIFAR-10 Batch 2:  loss:     1.2773\n",
      "validation accuracy:     0.4782\n",
      "Epoch 13, CIFAR-10 Batch 3:  loss:     1.2822\n",
      "validation accuracy:     0.4750\n",
      "Epoch 13, CIFAR-10 Batch 4:  loss:     1.3859\n",
      "validation accuracy:     0.4800\n",
      "Epoch 13, CIFAR-10 Batch 5:  loss:     1.2672\n",
      "validation accuracy:     0.4854\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss:     1.2599\n",
      "validation accuracy:     0.4734\n",
      "Epoch 14, CIFAR-10 Batch 2:  loss:     1.2187\n",
      "validation accuracy:     0.4908\n",
      "Epoch 14, CIFAR-10 Batch 3:  loss:     1.2566\n",
      "validation accuracy:     0.4828\n",
      "Epoch 14, CIFAR-10 Batch 4:  loss:     1.3541\n",
      "validation accuracy:     0.4806\n",
      "Epoch 14, CIFAR-10 Batch 5:  loss:     1.1642\n",
      "validation accuracy:     0.4928\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss:     1.2007\n",
      "validation accuracy:     0.4868\n",
      "Epoch 15, CIFAR-10 Batch 2:  loss:     1.2389\n",
      "validation accuracy:     0.4962\n",
      "Epoch 15, CIFAR-10 Batch 3:  loss:     1.2298\n",
      "validation accuracy:     0.4872\n",
      "Epoch 15, CIFAR-10 Batch 4:  loss:     1.2920\n",
      "validation accuracy:     0.4918\n",
      "Epoch 15, CIFAR-10 Batch 5:  loss:     1.1414\n",
      "validation accuracy:     0.4966\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss:     1.1647\n",
      "validation accuracy:     0.4768\n",
      "Epoch 16, CIFAR-10 Batch 2:  loss:     1.1742\n",
      "validation accuracy:     0.5024\n",
      "Epoch 16, CIFAR-10 Batch 3:  loss:     1.2101\n",
      "validation accuracy:     0.4916\n",
      "Epoch 16, CIFAR-10 Batch 4:  loss:     1.3013\n",
      "validation accuracy:     0.4914\n",
      "Epoch 16, CIFAR-10 Batch 5:  loss:     1.1534\n",
      "validation accuracy:     0.4980\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss:     1.1586\n",
      "validation accuracy:     0.4934\n",
      "Epoch 17, CIFAR-10 Batch 2:  loss:     1.1919\n",
      "validation accuracy:     0.5038\n",
      "Epoch 17, CIFAR-10 Batch 3:  loss:     1.1823\n",
      "validation accuracy:     0.4992\n",
      "Epoch 17, CIFAR-10 Batch 4:  loss:     1.2190\n",
      "validation accuracy:     0.5064\n",
      "Epoch 17, CIFAR-10 Batch 5:  loss:     1.0760\n",
      "validation accuracy:     0.5110\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss:     1.0712\n",
      "validation accuracy:     0.4982\n",
      "Epoch 18, CIFAR-10 Batch 2:  loss:     1.1771\n",
      "validation accuracy:     0.5074\n",
      "Epoch 18, CIFAR-10 Batch 3:  loss:     1.1772\n",
      "validation accuracy:     0.4934\n",
      "Epoch 18, CIFAR-10 Batch 4:  loss:     1.2162\n",
      "validation accuracy:     0.5048\n",
      "Epoch 18, CIFAR-10 Batch 5:  loss:     1.0662\n",
      "validation accuracy:     0.5150\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss:     1.0775\n",
      "validation accuracy:     0.5092\n",
      "Epoch 19, CIFAR-10 Batch 2:  loss:     1.1116\n",
      "validation accuracy:     0.5210\n",
      "Epoch 19, CIFAR-10 Batch 3:  loss:     1.0872\n",
      "validation accuracy:     0.5018\n",
      "Epoch 19, CIFAR-10 Batch 4:  loss:     1.1520\n",
      "validation accuracy:     0.5244\n",
      "Epoch 19, CIFAR-10 Batch 5:  loss:     1.0229\n",
      "validation accuracy:     0.5296\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss:     1.0365\n",
      "validation accuracy:     0.5104\n",
      "Epoch 20, CIFAR-10 Batch 2:  loss:     1.0555\n",
      "validation accuracy:     0.5268\n",
      "Epoch 20, CIFAR-10 Batch 3:  loss:     1.0173\n",
      "validation accuracy:     0.5146\n",
      "Epoch 20, CIFAR-10 Batch 4:  loss:     1.1325\n",
      "validation accuracy:     0.5242\n",
      "Epoch 20, CIFAR-10 Batch 5:  loss:     0.9953\n",
      "validation accuracy:     0.5414\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss:     1.0283\n",
      "validation accuracy:     0.5318\n",
      "Epoch 21, CIFAR-10 Batch 2:  loss:     1.0357\n",
      "validation accuracy:     0.5224\n",
      "Epoch 21, CIFAR-10 Batch 3:  loss:     0.9256\n",
      "validation accuracy:     0.5262\n",
      "Epoch 21, CIFAR-10 Batch 4:  loss:     1.1286\n",
      "validation accuracy:     0.5230\n",
      "Epoch 21, CIFAR-10 Batch 5:  loss:     0.9644\n",
      "validation accuracy:     0.5496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 1:  loss:     1.0680\n",
      "validation accuracy:     0.5408\n",
      "Epoch 22, CIFAR-10 Batch 2:  loss:     0.9752\n",
      "validation accuracy:     0.5400\n",
      "Epoch 22, CIFAR-10 Batch 3:  loss:     0.9535\n",
      "validation accuracy:     0.5318\n",
      "Epoch 22, CIFAR-10 Batch 4:  loss:     1.0745\n",
      "validation accuracy:     0.5488\n",
      "Epoch 22, CIFAR-10 Batch 5:  loss:     0.8919\n",
      "validation accuracy:     0.5518\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss:     0.9755\n",
      "validation accuracy:     0.5552\n",
      "Epoch 23, CIFAR-10 Batch 2:  loss:     0.9377\n",
      "validation accuracy:     0.5380\n",
      "Epoch 23, CIFAR-10 Batch 3:  loss:     0.9470\n",
      "validation accuracy:     0.5214\n",
      "Epoch 23, CIFAR-10 Batch 4:  loss:     1.0454\n",
      "validation accuracy:     0.5460\n",
      "Epoch 23, CIFAR-10 Batch 5:  loss:     0.9204\n",
      "validation accuracy:     0.5538\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss:     0.9875\n",
      "validation accuracy:     0.5532\n",
      "Epoch 24, CIFAR-10 Batch 2:  loss:     1.0101\n",
      "validation accuracy:     0.5370\n",
      "Epoch 24, CIFAR-10 Batch 3:  loss:     0.9592\n",
      "validation accuracy:     0.5336\n",
      "Epoch 24, CIFAR-10 Batch 4:  loss:     1.0064\n",
      "validation accuracy:     0.5468\n",
      "Epoch 24, CIFAR-10 Batch 5:  loss:     0.8329\n",
      "validation accuracy:     0.5570\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss:     0.9240\n",
      "validation accuracy:     0.5456\n",
      "Epoch 25, CIFAR-10 Batch 2:  loss:     0.8736\n",
      "validation accuracy:     0.5534\n",
      "Epoch 25, CIFAR-10 Batch 3:  loss:     0.9277\n",
      "validation accuracy:     0.5410\n",
      "Epoch 25, CIFAR-10 Batch 4:  loss:     1.0531\n",
      "validation accuracy:     0.5576\n",
      "Epoch 25, CIFAR-10 Batch 5:  loss:     0.8621\n",
      "validation accuracy:     0.5552\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss:     0.8771\n",
      "validation accuracy:     0.5562\n",
      "Epoch 26, CIFAR-10 Batch 2:  loss:     0.8569\n",
      "validation accuracy:     0.5652\n",
      "Epoch 26, CIFAR-10 Batch 3:  loss:     0.8822\n",
      "validation accuracy:     0.5452\n",
      "Epoch 26, CIFAR-10 Batch 4:  loss:     0.9909\n",
      "validation accuracy:     0.5672\n",
      "Epoch 26, CIFAR-10 Batch 5:  loss:     0.8141\n",
      "validation accuracy:     0.5666\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss:     0.9234\n",
      "validation accuracy:     0.5526\n",
      "Epoch 27, CIFAR-10 Batch 2:  loss:     0.8283\n",
      "validation accuracy:     0.5482\n",
      "Epoch 27, CIFAR-10 Batch 3:  loss:     0.8318\n",
      "validation accuracy:     0.5476\n",
      "Epoch 27, CIFAR-10 Batch 4:  loss:     0.9643\n",
      "validation accuracy:     0.5644\n",
      "Epoch 27, CIFAR-10 Batch 5:  loss:     0.7891\n",
      "validation accuracy:     0.5644\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss:     0.8630\n",
      "validation accuracy:     0.5530\n",
      "Epoch 28, CIFAR-10 Batch 2:  loss:     0.8750\n",
      "validation accuracy:     0.5568\n",
      "Epoch 28, CIFAR-10 Batch 3:  loss:     0.8186\n",
      "validation accuracy:     0.5518\n",
      "Epoch 28, CIFAR-10 Batch 4:  loss:     0.9638\n",
      "validation accuracy:     0.5486\n",
      "Epoch 28, CIFAR-10 Batch 5:  loss:     0.7538\n",
      "validation accuracy:     0.5666\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss:     0.8582\n",
      "validation accuracy:     0.5402\n",
      "Epoch 29, CIFAR-10 Batch 2:  loss:     0.9040\n",
      "validation accuracy:     0.5538\n",
      "Epoch 29, CIFAR-10 Batch 3:  loss:     0.8141\n",
      "validation accuracy:     0.5544\n",
      "Epoch 29, CIFAR-10 Batch 4:  loss:     0.9088\n",
      "validation accuracy:     0.5596\n",
      "Epoch 29, CIFAR-10 Batch 5:  loss:     0.8213\n",
      "validation accuracy:     0.5640\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss:     0.7849\n",
      "validation accuracy:     0.5538\n",
      "Epoch 30, CIFAR-10 Batch 2:  loss:     0.8098\n",
      "validation accuracy:     0.5662\n",
      "Epoch 30, CIFAR-10 Batch 3:  loss:     0.8471\n",
      "validation accuracy:     0.5530\n",
      "Epoch 30, CIFAR-10 Batch 4:  loss:     0.8710\n",
      "validation accuracy:     0.5646\n",
      "Epoch 30, CIFAR-10 Batch 5:  loss:     0.7564\n",
      "validation accuracy:     0.5640\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss:     0.7633\n",
      "validation accuracy:     0.5696\n",
      "Epoch 31, CIFAR-10 Batch 2:  loss:     0.8275\n",
      "validation accuracy:     0.5578\n",
      "Epoch 31, CIFAR-10 Batch 3:  loss:     0.7568\n",
      "validation accuracy:     0.5676\n",
      "Epoch 31, CIFAR-10 Batch 4:  loss:     0.9070\n",
      "validation accuracy:     0.5746\n",
      "Epoch 31, CIFAR-10 Batch 5:  loss:     0.7311\n",
      "validation accuracy:     0.5684\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss:     0.7683\n",
      "validation accuracy:     0.5692\n",
      "Epoch 32, CIFAR-10 Batch 2:  loss:     0.8121\n",
      "validation accuracy:     0.5656\n",
      "Epoch 32, CIFAR-10 Batch 3:  loss:     0.8086\n",
      "validation accuracy:     0.5476\n",
      "Epoch 32, CIFAR-10 Batch 4:  loss:     0.8900\n",
      "validation accuracy:     0.5676\n",
      "Epoch 32, CIFAR-10 Batch 5:  loss:     0.7342\n",
      "validation accuracy:     0.5690\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss:     0.7710\n",
      "validation accuracy:     0.5736\n",
      "Epoch 33, CIFAR-10 Batch 2:  loss:     0.7863\n",
      "validation accuracy:     0.5582\n",
      "Epoch 33, CIFAR-10 Batch 3:  loss:     0.7890\n",
      "validation accuracy:     0.5492\n",
      "Epoch 33, CIFAR-10 Batch 4:  loss:     0.8724\n",
      "validation accuracy:     0.5666\n",
      "Epoch 33, CIFAR-10 Batch 5:  loss:     0.7167\n",
      "validation accuracy:     0.5768\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss:     0.7769\n",
      "validation accuracy:     0.5734\n",
      "Epoch 34, CIFAR-10 Batch 2:  loss:     0.7673\n",
      "validation accuracy:     0.5534\n",
      "Epoch 34, CIFAR-10 Batch 3:  loss:     0.7389\n",
      "validation accuracy:     0.5586\n",
      "Epoch 34, CIFAR-10 Batch 4:  loss:     0.8309\n",
      "validation accuracy:     0.5644\n",
      "Epoch 34, CIFAR-10 Batch 5:  loss:     0.6853\n",
      "validation accuracy:     0.5626\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss:     0.7057\n",
      "validation accuracy:     0.5616\n",
      "Epoch 35, CIFAR-10 Batch 2:  loss:     0.7294\n",
      "validation accuracy:     0.5588\n",
      "Epoch 35, CIFAR-10 Batch 3:  loss:     0.7243\n",
      "validation accuracy:     0.5494\n",
      "Epoch 35, CIFAR-10 Batch 4:  loss:     0.8349\n",
      "validation accuracy:     0.5602\n",
      "Epoch 35, CIFAR-10 Batch 5:  loss:     0.7094\n",
      "validation accuracy:     0.5680\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss:     0.6910\n",
      "validation accuracy:     0.5682\n",
      "Epoch 36, CIFAR-10 Batch 2:  loss:     0.7696\n",
      "validation accuracy:     0.5600\n",
      "Epoch 36, CIFAR-10 Batch 3:  loss:     0.6881\n",
      "validation accuracy:     0.5654\n",
      "Epoch 36, CIFAR-10 Batch 4:  loss:     0.8295\n",
      "validation accuracy:     0.5704\n",
      "Epoch 36, CIFAR-10 Batch 5:  loss:     0.6817\n",
      "validation accuracy:     0.5642\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss:     0.7198\n",
      "validation accuracy:     0.5644\n",
      "Epoch 37, CIFAR-10 Batch 2:  loss:     0.7596\n",
      "validation accuracy:     0.5544\n",
      "Epoch 37, CIFAR-10 Batch 3:  loss:     0.6650\n",
      "validation accuracy:     0.5576\n",
      "Epoch 37, CIFAR-10 Batch 4:  loss:     0.8302\n",
      "validation accuracy:     0.5712\n",
      "Epoch 37, CIFAR-10 Batch 5:  loss:     0.6572\n",
      "validation accuracy:     0.5760\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss:     0.6610\n",
      "validation accuracy:     0.5788\n",
      "Epoch 38, CIFAR-10 Batch 2:  loss:     0.7278\n",
      "validation accuracy:     0.5588\n",
      "Epoch 38, CIFAR-10 Batch 3:  loss:     0.6574\n",
      "validation accuracy:     0.5654\n",
      "Epoch 38, CIFAR-10 Batch 4:  loss:     0.7934\n",
      "validation accuracy:     0.5708\n",
      "Epoch 38, CIFAR-10 Batch 5:  loss:     0.6536\n",
      "validation accuracy:     0.5618\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss:     0.6377\n",
      "validation accuracy:     0.5758\n",
      "Epoch 39, CIFAR-10 Batch 2:  loss:     0.7190\n",
      "validation accuracy:     0.5526\n",
      "Epoch 39, CIFAR-10 Batch 3:  loss:     0.6764\n",
      "validation accuracy:     0.5512\n",
      "Epoch 39, CIFAR-10 Batch 4:  loss:     0.7898\n",
      "validation accuracy:     0.5608\n",
      "Epoch 39, CIFAR-10 Batch 5:  loss:     0.6676\n",
      "validation accuracy:     0.5614\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss:     0.6672\n",
      "validation accuracy:     0.5732\n",
      "Epoch 40, CIFAR-10 Batch 2:  loss:     0.7390\n",
      "validation accuracy:     0.5580\n",
      "Epoch 40, CIFAR-10 Batch 3:  loss:     0.6625\n",
      "validation accuracy:     0.5516\n",
      "Epoch 40, CIFAR-10 Batch 4:  loss:     0.8034\n",
      "validation accuracy:     0.5620\n",
      "Epoch 40, CIFAR-10 Batch 5:  loss:     0.6550\n",
      "validation accuracy:     0.5680\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss:     0.6302\n",
      "validation accuracy:     0.5622\n",
      "Epoch 41, CIFAR-10 Batch 2:  loss:     0.7018\n",
      "validation accuracy:     0.5610\n",
      "Epoch 41, CIFAR-10 Batch 3:  loss:     0.6690\n",
      "validation accuracy:     0.5602\n",
      "Epoch 41, CIFAR-10 Batch 4:  loss:     0.8009\n",
      "validation accuracy:     0.5680\n",
      "Epoch 41, CIFAR-10 Batch 5:  loss:     0.6579\n",
      "validation accuracy:     0.5656\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss:     0.6601\n",
      "validation accuracy:     0.5612\n",
      "Epoch 42, CIFAR-10 Batch 2:  loss:     0.6338\n",
      "validation accuracy:     0.5652\n",
      "Epoch 42, CIFAR-10 Batch 3:  loss:     0.6263\n",
      "validation accuracy:     0.5494\n",
      "Epoch 42, CIFAR-10 Batch 4:  loss:     0.8248\n",
      "validation accuracy:     0.5690\n",
      "Epoch 42, CIFAR-10 Batch 5:  loss:     0.6083\n",
      "validation accuracy:     0.5682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 1:  loss:     0.6236\n",
      "validation accuracy:     0.5676\n",
      "Epoch 43, CIFAR-10 Batch 2:  loss:     0.6843\n",
      "validation accuracy:     0.5520\n",
      "Epoch 43, CIFAR-10 Batch 3:  loss:     0.6172\n",
      "validation accuracy:     0.5374\n",
      "Epoch 43, CIFAR-10 Batch 4:  loss:     0.8127\n",
      "validation accuracy:     0.5650\n",
      "Epoch 43, CIFAR-10 Batch 5:  loss:     0.7233\n",
      "validation accuracy:     0.5402\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss:     0.6404\n",
      "validation accuracy:     0.5656\n",
      "Epoch 44, CIFAR-10 Batch 2:  loss:     0.7015\n",
      "validation accuracy:     0.5544\n",
      "Epoch 44, CIFAR-10 Batch 3:  loss:     0.7226\n",
      "validation accuracy:     0.5470\n",
      "Epoch 44, CIFAR-10 Batch 4:  loss:     0.8423\n",
      "validation accuracy:     0.5754\n",
      "Epoch 44, CIFAR-10 Batch 5:  loss:     0.6911\n",
      "validation accuracy:     0.5538\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss:     0.6490\n",
      "validation accuracy:     0.5536\n",
      "Epoch 45, CIFAR-10 Batch 2:  loss:     0.7020\n",
      "validation accuracy:     0.5716\n",
      "Epoch 45, CIFAR-10 Batch 3:  loss:     0.5928\n",
      "validation accuracy:     0.5598\n",
      "Epoch 45, CIFAR-10 Batch 4:  loss:     0.7429\n",
      "validation accuracy:     0.5764\n",
      "Epoch 45, CIFAR-10 Batch 5:  loss:     0.5589\n",
      "validation accuracy:     0.5604\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss:     0.5716\n",
      "validation accuracy:     0.5498\n",
      "Epoch 46, CIFAR-10 Batch 2:  loss:     0.6379\n",
      "validation accuracy:     0.5696\n",
      "Epoch 46, CIFAR-10 Batch 3:  loss:     0.5891\n",
      "validation accuracy:     0.5500\n",
      "Epoch 46, CIFAR-10 Batch 4:  loss:     0.7626\n",
      "validation accuracy:     0.5652\n",
      "Epoch 46, CIFAR-10 Batch 5:  loss:     0.7040\n",
      "validation accuracy:     0.5430\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss:     0.5710\n",
      "validation accuracy:     0.5718\n",
      "Epoch 47, CIFAR-10 Batch 2:  loss:     0.6944\n",
      "validation accuracy:     0.5470\n",
      "Epoch 47, CIFAR-10 Batch 3:  loss:     0.6075\n",
      "validation accuracy:     0.5508\n",
      "Epoch 47, CIFAR-10 Batch 4:  loss:     0.7705\n",
      "validation accuracy:     0.5548\n",
      "Epoch 47, CIFAR-10 Batch 5:  loss:     0.6913\n",
      "validation accuracy:     0.5442\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss:     0.6246\n",
      "validation accuracy:     0.5450\n",
      "Epoch 48, CIFAR-10 Batch 2:  loss:     0.6383\n",
      "validation accuracy:     0.5558\n",
      "Epoch 48, CIFAR-10 Batch 3:  loss:     0.5726\n",
      "validation accuracy:     0.5440\n",
      "Epoch 48, CIFAR-10 Batch 4:  loss:     0.7507\n",
      "validation accuracy:     0.5772\n",
      "Epoch 48, CIFAR-10 Batch 5:  loss:     0.6251\n",
      "validation accuracy:     0.5440\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss:     0.6167\n",
      "validation accuracy:     0.5628\n",
      "Epoch 49, CIFAR-10 Batch 2:  loss:     0.6380\n",
      "validation accuracy:     0.5628\n",
      "Epoch 49, CIFAR-10 Batch 3:  loss:     0.6893\n",
      "validation accuracy:     0.5182\n",
      "Epoch 49, CIFAR-10 Batch 4:  loss:     0.7481\n",
      "validation accuracy:     0.5736\n",
      "Epoch 49, CIFAR-10 Batch 5:  loss:     0.5973\n",
      "validation accuracy:     0.5592\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss:     0.5649\n",
      "validation accuracy:     0.5596\n",
      "Epoch 50, CIFAR-10 Batch 2:  loss:     0.6290\n",
      "validation accuracy:     0.5622\n",
      "Epoch 50, CIFAR-10 Batch 3:  loss:     0.6592\n",
      "validation accuracy:     0.5400\n",
      "Epoch 50, CIFAR-10 Batch 4:  loss:     0.7986\n",
      "validation accuracy:     0.5640\n",
      "Epoch 50, CIFAR-10 Batch 5:  loss:     0.5881\n",
      "validation accuracy:     0.5472\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss:     0.5789\n",
      "validation accuracy:     0.5498\n",
      "Epoch 51, CIFAR-10 Batch 2:  loss:     0.6756\n",
      "validation accuracy:     0.5532\n",
      "Epoch 51, CIFAR-10 Batch 3:  loss:     0.5950\n",
      "validation accuracy:     0.5346\n",
      "Epoch 51, CIFAR-10 Batch 4:  loss:     0.7427\n",
      "validation accuracy:     0.5796\n",
      "Epoch 51, CIFAR-10 Batch 5:  loss:     0.6064\n",
      "validation accuracy:     0.5524\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss:     0.5451\n",
      "validation accuracy:     0.5684\n",
      "Epoch 52, CIFAR-10 Batch 2:  loss:     0.6450\n",
      "validation accuracy:     0.5496\n",
      "Epoch 52, CIFAR-10 Batch 3:  loss:     0.5716\n",
      "validation accuracy:     0.5520\n",
      "Epoch 52, CIFAR-10 Batch 4:  loss:     0.7943\n",
      "validation accuracy:     0.5732\n",
      "Epoch 52, CIFAR-10 Batch 5:  loss:     0.5930\n",
      "validation accuracy:     0.5456\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss:     0.5425\n",
      "validation accuracy:     0.5612\n",
      "Epoch 53, CIFAR-10 Batch 2:  loss:     0.6244\n",
      "validation accuracy:     0.5578\n",
      "Epoch 53, CIFAR-10 Batch 3:  loss:     0.6079\n",
      "validation accuracy:     0.5444\n",
      "Epoch 53, CIFAR-10 Batch 4:  loss:     0.7379\n",
      "validation accuracy:     0.5668\n",
      "Epoch 53, CIFAR-10 Batch 5:  loss:     0.6471\n",
      "validation accuracy:     0.5372\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss:     0.5563\n",
      "validation accuracy:     0.5564\n",
      "Epoch 54, CIFAR-10 Batch 2:  loss:     0.6497\n",
      "validation accuracy:     0.5540\n",
      "Epoch 54, CIFAR-10 Batch 3:  loss:     0.5956\n",
      "validation accuracy:     0.5510\n",
      "Epoch 54, CIFAR-10 Batch 4:  loss:     0.7510\n",
      "validation accuracy:     0.5716\n",
      "Epoch 54, CIFAR-10 Batch 5:  loss:     0.5946\n",
      "validation accuracy:     0.5314\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss:     0.5552\n",
      "validation accuracy:     0.5546\n",
      "Epoch 55, CIFAR-10 Batch 2:  loss:     0.7063\n",
      "validation accuracy:     0.5496\n",
      "Epoch 55, CIFAR-10 Batch 3:  loss:     0.5871\n",
      "validation accuracy:     0.5328\n",
      "Epoch 55, CIFAR-10 Batch 4:  loss:     0.7641\n",
      "validation accuracy:     0.5688\n",
      "Epoch 55, CIFAR-10 Batch 5:  loss:     0.6142\n",
      "validation accuracy:     0.5298\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss:     0.5588\n",
      "validation accuracy:     0.5600\n",
      "Epoch 56, CIFAR-10 Batch 2:  loss:     0.6095\n",
      "validation accuracy:     0.5602\n",
      "Epoch 56, CIFAR-10 Batch 3:  loss:     0.6022\n",
      "validation accuracy:     0.5414\n",
      "Epoch 56, CIFAR-10 Batch 4:  loss:     0.7533\n",
      "validation accuracy:     0.5610\n",
      "Epoch 56, CIFAR-10 Batch 5:  loss:     0.5930\n",
      "validation accuracy:     0.5482\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss:     0.5979\n",
      "validation accuracy:     0.5512\n",
      "Epoch 57, CIFAR-10 Batch 2:  loss:     0.6495\n",
      "validation accuracy:     0.5588\n",
      "Epoch 57, CIFAR-10 Batch 3:  loss:     0.7104\n",
      "validation accuracy:     0.5132\n",
      "Epoch 57, CIFAR-10 Batch 4:  loss:     0.7721\n",
      "validation accuracy:     0.5686\n",
      "Epoch 57, CIFAR-10 Batch 5:  loss:     0.5385\n",
      "validation accuracy:     0.5548\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss:     0.5200\n",
      "validation accuracy:     0.5610\n",
      "Epoch 58, CIFAR-10 Batch 2:  loss:     0.5632\n",
      "validation accuracy:     0.5604\n",
      "Epoch 58, CIFAR-10 Batch 3:  loss:     0.6039\n",
      "validation accuracy:     0.5376\n",
      "Epoch 58, CIFAR-10 Batch 4:  loss:     0.7322\n",
      "validation accuracy:     0.5570\n",
      "Epoch 58, CIFAR-10 Batch 5:  loss:     0.5702\n",
      "validation accuracy:     0.5488\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss:     0.5137\n",
      "validation accuracy:     0.5612\n",
      "Epoch 59, CIFAR-10 Batch 2:  loss:     0.6526\n",
      "validation accuracy:     0.5540\n",
      "Epoch 59, CIFAR-10 Batch 3:  loss:     0.5531\n",
      "validation accuracy:     0.5482\n",
      "Epoch 59, CIFAR-10 Batch 4:  loss:     0.7105\n",
      "validation accuracy:     0.5632\n",
      "Epoch 59, CIFAR-10 Batch 5:  loss:     0.5563\n",
      "validation accuracy:     0.5580\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss:     0.4996\n",
      "validation accuracy:     0.5578\n",
      "Epoch 60, CIFAR-10 Batch 2:  loss:     0.6211\n",
      "validation accuracy:     0.5672\n",
      "Epoch 60, CIFAR-10 Batch 3:  loss:     0.5683\n",
      "validation accuracy:     0.5412\n",
      "Epoch 60, CIFAR-10 Batch 4:  loss:     0.6874\n",
      "validation accuracy:     0.5630\n",
      "Epoch 60, CIFAR-10 Batch 5:  loss:     0.5169\n",
      "validation accuracy:     0.5374\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss:     0.5161\n",
      "validation accuracy:     0.5548\n",
      "Epoch 61, CIFAR-10 Batch 2:  loss:     0.6301\n",
      "validation accuracy:     0.5504\n",
      "Epoch 61, CIFAR-10 Batch 3:  loss:     0.6440\n",
      "validation accuracy:     0.5244\n",
      "Epoch 61, CIFAR-10 Batch 4:  loss:     0.6818\n",
      "validation accuracy:     0.5682\n",
      "Epoch 61, CIFAR-10 Batch 5:  loss:     0.5237\n",
      "validation accuracy:     0.5514\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss:     0.4657\n",
      "validation accuracy:     0.5608\n",
      "Epoch 62, CIFAR-10 Batch 2:  loss:     0.6292\n",
      "validation accuracy:     0.5502\n",
      "Epoch 62, CIFAR-10 Batch 3:  loss:     0.6064\n",
      "validation accuracy:     0.5348\n",
      "Epoch 62, CIFAR-10 Batch 4:  loss:     0.7114\n",
      "validation accuracy:     0.5632\n",
      "Epoch 62, CIFAR-10 Batch 5:  loss:     0.5193\n",
      "validation accuracy:     0.5574\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss:     0.4614\n",
      "validation accuracy:     0.5520\n",
      "Epoch 63, CIFAR-10 Batch 2:  loss:     0.6000\n",
      "validation accuracy:     0.5582\n",
      "Epoch 63, CIFAR-10 Batch 3:  loss:     0.5880\n",
      "validation accuracy:     0.5122\n",
      "Epoch 63, CIFAR-10 Batch 4:  loss:     0.7107\n",
      "validation accuracy:     0.5536\n",
      "Epoch 63, CIFAR-10 Batch 5:  loss:     0.4830\n",
      "validation accuracy:     0.5444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, CIFAR-10 Batch 1:  loss:     0.4703\n",
      "validation accuracy:     0.5566\n",
      "Epoch 64, CIFAR-10 Batch 2:  loss:     0.5602\n",
      "validation accuracy:     0.5508\n",
      "Epoch 64, CIFAR-10 Batch 3:  loss:     0.5646\n",
      "validation accuracy:     0.5218\n",
      "Epoch 64, CIFAR-10 Batch 4:  loss:     0.6719\n",
      "validation accuracy:     0.5634\n",
      "Epoch 64, CIFAR-10 Batch 5:  loss:     0.5179\n",
      "validation accuracy:     0.5482\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss:     0.4616\n",
      "validation accuracy:     0.5670\n",
      "Epoch 65, CIFAR-10 Batch 2:  loss:     0.6332\n",
      "validation accuracy:     0.5512\n",
      "Epoch 65, CIFAR-10 Batch 3:  loss:     0.6186\n",
      "validation accuracy:     0.5212\n",
      "Epoch 65, CIFAR-10 Batch 4:  loss:     0.6729\n",
      "validation accuracy:     0.5588\n",
      "Epoch 65, CIFAR-10 Batch 5:  loss:     0.5303\n",
      "validation accuracy:     0.5462\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss:     0.5374\n",
      "validation accuracy:     0.5484\n",
      "Epoch 66, CIFAR-10 Batch 2:  loss:     0.5216\n",
      "validation accuracy:     0.5578\n",
      "Epoch 66, CIFAR-10 Batch 3:  loss:     0.6092\n",
      "validation accuracy:     0.5364\n",
      "Epoch 66, CIFAR-10 Batch 4:  loss:     0.6481\n",
      "validation accuracy:     0.5534\n",
      "Epoch 66, CIFAR-10 Batch 5:  loss:     0.4722\n",
      "validation accuracy:     0.5456\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss:     0.5417\n",
      "validation accuracy:     0.5482\n",
      "Epoch 67, CIFAR-10 Batch 2:  loss:     0.5857\n",
      "validation accuracy:     0.5490\n",
      "Epoch 67, CIFAR-10 Batch 3:  loss:     0.5088\n",
      "validation accuracy:     0.5376\n",
      "Epoch 67, CIFAR-10 Batch 4:  loss:     0.6235\n",
      "validation accuracy:     0.5628\n",
      "Epoch 67, CIFAR-10 Batch 5:  loss:     0.4402\n",
      "validation accuracy:     0.5610\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss:     0.4538\n",
      "validation accuracy:     0.5588\n",
      "Epoch 68, CIFAR-10 Batch 2:  loss:     0.5420\n",
      "validation accuracy:     0.5550\n",
      "Epoch 68, CIFAR-10 Batch 3:  loss:     0.5465\n",
      "validation accuracy:     0.5264\n",
      "Epoch 68, CIFAR-10 Batch 4:  loss:     0.6530\n",
      "validation accuracy:     0.5524\n",
      "Epoch 68, CIFAR-10 Batch 5:  loss:     0.4579\n",
      "validation accuracy:     0.5520\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss:     0.4579\n",
      "validation accuracy:     0.5556\n",
      "Epoch 69, CIFAR-10 Batch 2:  loss:     0.5131\n",
      "validation accuracy:     0.5552\n",
      "Epoch 69, CIFAR-10 Batch 3:  loss:     0.5470\n",
      "validation accuracy:     0.5494\n",
      "Epoch 69, CIFAR-10 Batch 4:  loss:     0.6599\n",
      "validation accuracy:     0.5578\n",
      "Epoch 69, CIFAR-10 Batch 5:  loss:     0.4792\n",
      "validation accuracy:     0.5564\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss:     0.4415\n",
      "validation accuracy:     0.5462\n",
      "Epoch 70, CIFAR-10 Batch 2:  loss:     0.5220\n",
      "validation accuracy:     0.5544\n",
      "Epoch 70, CIFAR-10 Batch 3:  loss:     0.5318\n",
      "validation accuracy:     0.5470\n",
      "Epoch 70, CIFAR-10 Batch 4:  loss:     0.6458\n",
      "validation accuracy:     0.5536\n",
      "Epoch 70, CIFAR-10 Batch 5:  loss:     0.4504\n",
      "validation accuracy:     0.5574\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss:     0.4928\n",
      "validation accuracy:     0.5546\n",
      "Epoch 71, CIFAR-10 Batch 2:  loss:     0.5778\n",
      "validation accuracy:     0.5486\n",
      "Epoch 71, CIFAR-10 Batch 3:  loss:     0.5049\n",
      "validation accuracy:     0.5106\n",
      "Epoch 71, CIFAR-10 Batch 4:  loss:     0.6130\n",
      "validation accuracy:     0.5562\n",
      "Epoch 71, CIFAR-10 Batch 5:  loss:     0.4149\n",
      "validation accuracy:     0.5536\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss:     0.4491\n",
      "validation accuracy:     0.5604\n",
      "Epoch 72, CIFAR-10 Batch 2:  loss:     0.5016\n",
      "validation accuracy:     0.5562\n",
      "Epoch 72, CIFAR-10 Batch 3:  loss:     0.5391\n",
      "validation accuracy:     0.5340\n",
      "Epoch 72, CIFAR-10 Batch 4:  loss:     0.6313\n",
      "validation accuracy:     0.5536\n",
      "Epoch 72, CIFAR-10 Batch 5:  loss:     0.4164\n",
      "validation accuracy:     0.5570\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss:     0.4739\n",
      "validation accuracy:     0.5578\n",
      "Epoch 73, CIFAR-10 Batch 2:  loss:     0.5260\n",
      "validation accuracy:     0.5544\n",
      "Epoch 73, CIFAR-10 Batch 3:  loss:     0.5427\n",
      "validation accuracy:     0.5366\n",
      "Epoch 73, CIFAR-10 Batch 4:  loss:     0.6016\n",
      "validation accuracy:     0.5584\n",
      "Epoch 73, CIFAR-10 Batch 5:  loss:     0.4648\n",
      "validation accuracy:     0.5638\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss:     0.4708\n",
      "validation accuracy:     0.5552\n",
      "Epoch 74, CIFAR-10 Batch 2:  loss:     0.4896\n",
      "validation accuracy:     0.5526\n",
      "Epoch 74, CIFAR-10 Batch 3:  loss:     0.5374\n",
      "validation accuracy:     0.5318\n",
      "Epoch 74, CIFAR-10 Batch 4:  loss:     0.6189\n",
      "validation accuracy:     0.5526\n",
      "Epoch 74, CIFAR-10 Batch 5:  loss:     0.4233\n",
      "validation accuracy:     0.5526\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss:     0.4340\n",
      "validation accuracy:     0.5462\n",
      "Epoch 75, CIFAR-10 Batch 2:  loss:     0.5128\n",
      "validation accuracy:     0.5548\n",
      "Epoch 75, CIFAR-10 Batch 3:  loss:     0.5373\n",
      "validation accuracy:     0.5286\n",
      "Epoch 75, CIFAR-10 Batch 4:  loss:     0.6081\n",
      "validation accuracy:     0.5550\n",
      "Epoch 75, CIFAR-10 Batch 5:  loss:     0.4114\n",
      "validation accuracy:     0.5478\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss:     0.4760\n",
      "validation accuracy:     0.5410\n",
      "Epoch 76, CIFAR-10 Batch 2:  loss:     0.5353\n",
      "validation accuracy:     0.5382\n",
      "Epoch 76, CIFAR-10 Batch 3:  loss:     0.4922\n",
      "validation accuracy:     0.5392\n",
      "Epoch 76, CIFAR-10 Batch 4:  loss:     0.6029\n",
      "validation accuracy:     0.5488\n",
      "Epoch 76, CIFAR-10 Batch 5:  loss:     0.4483\n",
      "validation accuracy:     0.5532\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss:     0.4705\n",
      "validation accuracy:     0.5422\n",
      "Epoch 77, CIFAR-10 Batch 2:  loss:     0.5294\n",
      "validation accuracy:     0.5482\n",
      "Epoch 77, CIFAR-10 Batch 3:  loss:     0.4979\n",
      "validation accuracy:     0.5384\n",
      "Epoch 77, CIFAR-10 Batch 4:  loss:     0.6228\n",
      "validation accuracy:     0.5548\n",
      "Epoch 77, CIFAR-10 Batch 5:  loss:     0.4388\n",
      "validation accuracy:     0.5510\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss:     0.4222\n",
      "validation accuracy:     0.5466\n",
      "Epoch 78, CIFAR-10 Batch 2:  loss:     0.5570\n",
      "validation accuracy:     0.5552\n",
      "Epoch 78, CIFAR-10 Batch 3:  loss:     0.5492\n",
      "validation accuracy:     0.5214\n",
      "Epoch 78, CIFAR-10 Batch 4:  loss:     0.5650\n",
      "validation accuracy:     0.5474\n",
      "Epoch 78, CIFAR-10 Batch 5:  loss:     0.4275\n",
      "validation accuracy:     0.5610\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss:     0.4478\n",
      "validation accuracy:     0.5488\n",
      "Epoch 79, CIFAR-10 Batch 2:  loss:     0.5898\n",
      "validation accuracy:     0.5412\n",
      "Epoch 79, CIFAR-10 Batch 3:  loss:     0.5247\n",
      "validation accuracy:     0.5320\n",
      "Epoch 79, CIFAR-10 Batch 4:  loss:     0.7158\n",
      "validation accuracy:     0.5500\n",
      "Epoch 79, CIFAR-10 Batch 5:  loss:     0.5144\n",
      "validation accuracy:     0.5440\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss:     0.5033\n",
      "validation accuracy:     0.5436\n",
      "Epoch 80, CIFAR-10 Batch 2:  loss:     0.5692\n",
      "validation accuracy:     0.5392\n",
      "Epoch 80, CIFAR-10 Batch 3:  loss:     0.5216\n",
      "validation accuracy:     0.5286\n",
      "Epoch 80, CIFAR-10 Batch 4:  loss:     0.5866\n",
      "validation accuracy:     0.5534\n",
      "Epoch 80, CIFAR-10 Batch 5:  loss:     0.4701\n",
      "validation accuracy:     0.5470\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss:     0.5440\n",
      "validation accuracy:     0.5424\n",
      "Epoch 81, CIFAR-10 Batch 2:  loss:     0.4940\n",
      "validation accuracy:     0.5466\n",
      "Epoch 81, CIFAR-10 Batch 3:  loss:     0.4464\n",
      "validation accuracy:     0.5484\n",
      "Epoch 81, CIFAR-10 Batch 4:  loss:     0.5824\n",
      "validation accuracy:     0.5582\n",
      "Epoch 81, CIFAR-10 Batch 5:  loss:     0.4381\n",
      "validation accuracy:     0.5424\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss:     0.5023\n",
      "validation accuracy:     0.5446\n",
      "Epoch 82, CIFAR-10 Batch 2:  loss:     0.5208\n",
      "validation accuracy:     0.5390\n",
      "Epoch 82, CIFAR-10 Batch 3:  loss:     0.5101\n",
      "validation accuracy:     0.5310\n",
      "Epoch 82, CIFAR-10 Batch 4:  loss:     0.6027\n",
      "validation accuracy:     0.5556\n",
      "Epoch 82, CIFAR-10 Batch 5:  loss:     0.4247\n",
      "validation accuracy:     0.5476\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss:     0.4904\n",
      "validation accuracy:     0.5386\n",
      "Epoch 83, CIFAR-10 Batch 2:  loss:     0.4922\n",
      "validation accuracy:     0.5398\n",
      "Epoch 83, CIFAR-10 Batch 3:  loss:     0.4651\n",
      "validation accuracy:     0.5300\n",
      "Epoch 83, CIFAR-10 Batch 4:  loss:     0.5890\n",
      "validation accuracy:     0.5504\n",
      "Epoch 83, CIFAR-10 Batch 5:  loss:     0.4756\n",
      "validation accuracy:     0.5478\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss:     0.4702\n",
      "validation accuracy:     0.5386\n",
      "Epoch 84, CIFAR-10 Batch 2:  loss:     0.4711\n",
      "validation accuracy:     0.5364\n",
      "Epoch 84, CIFAR-10 Batch 3:  loss:     0.4561\n",
      "validation accuracy:     0.5446\n",
      "Epoch 84, CIFAR-10 Batch 4:  loss:     0.5406\n",
      "validation accuracy:     0.5482\n",
      "Epoch 84, CIFAR-10 Batch 5:  loss:     0.4677\n",
      "validation accuracy:     0.5368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, CIFAR-10 Batch 1:  loss:     0.4549\n",
      "validation accuracy:     0.5398\n",
      "Epoch 85, CIFAR-10 Batch 2:  loss:     0.4336\n",
      "validation accuracy:     0.5532\n",
      "Epoch 85, CIFAR-10 Batch 3:  loss:     0.4721\n",
      "validation accuracy:     0.5490\n",
      "Epoch 85, CIFAR-10 Batch 4:  loss:     0.5511\n",
      "validation accuracy:     0.5528\n",
      "Epoch 85, CIFAR-10 Batch 5:  loss:     0.4157\n",
      "validation accuracy:     0.5524\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss:     0.5080\n",
      "validation accuracy:     0.5328\n",
      "Epoch 86, CIFAR-10 Batch 2:  loss:     0.4267\n",
      "validation accuracy:     0.5456\n",
      "Epoch 86, CIFAR-10 Batch 3:  loss:     0.5299\n",
      "validation accuracy:     0.5404\n",
      "Epoch 86, CIFAR-10 Batch 4:  loss:     0.6024\n",
      "validation accuracy:     0.5482\n",
      "Epoch 86, CIFAR-10 Batch 5:  loss:     0.4186\n",
      "validation accuracy:     0.5418\n",
      "Epoch 87, CIFAR-10 Batch 1:  loss:     0.5120\n",
      "validation accuracy:     0.5400\n",
      "Epoch 87, CIFAR-10 Batch 2:  loss:     0.4508\n",
      "validation accuracy:     0.5514\n",
      "Epoch 87, CIFAR-10 Batch 3:  loss:     0.4555\n",
      "validation accuracy:     0.5390\n",
      "Epoch 87, CIFAR-10 Batch 4:  loss:     0.6272\n",
      "validation accuracy:     0.5540\n",
      "Epoch 87, CIFAR-10 Batch 5:  loss:     0.4009\n",
      "validation accuracy:     0.5476\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss:     0.4454\n",
      "validation accuracy:     0.5256\n",
      "Epoch 88, CIFAR-10 Batch 2:  loss:     0.4685\n",
      "validation accuracy:     0.5504\n",
      "Epoch 88, CIFAR-10 Batch 3:  loss:     0.4789\n",
      "validation accuracy:     0.5390\n",
      "Epoch 88, CIFAR-10 Batch 4:  loss:     0.6045\n",
      "validation accuracy:     0.5464\n",
      "Epoch 88, CIFAR-10 Batch 5:  loss:     0.4362\n",
      "validation accuracy:     0.5344\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss:     0.4752\n",
      "validation accuracy:     0.5422\n",
      "Epoch 89, CIFAR-10 Batch 2:  loss:     0.4586\n",
      "validation accuracy:     0.5510\n",
      "Epoch 89, CIFAR-10 Batch 3:  loss:     0.4441\n",
      "validation accuracy:     0.5292\n",
      "Epoch 89, CIFAR-10 Batch 4:  loss:     0.6622\n",
      "validation accuracy:     0.5474\n",
      "Epoch 89, CIFAR-10 Batch 5:  loss:     0.4260\n",
      "validation accuracy:     0.5492\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss:     0.4422\n",
      "validation accuracy:     0.5340\n",
      "Epoch 90, CIFAR-10 Batch 2:  loss:     0.4967\n",
      "validation accuracy:     0.5454\n",
      "Epoch 90, CIFAR-10 Batch 3:  loss:     0.4544\n",
      "validation accuracy:     0.5424\n",
      "Epoch 90, CIFAR-10 Batch 4:  loss:     0.5472\n",
      "validation accuracy:     0.5498\n",
      "Epoch 90, CIFAR-10 Batch 5:  loss:     0.4141\n",
      "validation accuracy:     0.5348\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss:     0.4543\n",
      "validation accuracy:     0.5452\n",
      "Epoch 91, CIFAR-10 Batch 2:  loss:     0.6031\n",
      "validation accuracy:     0.5458\n",
      "Epoch 91, CIFAR-10 Batch 3:  loss:     0.5258\n",
      "validation accuracy:     0.5418\n",
      "Epoch 91, CIFAR-10 Batch 4:  loss:     0.5473\n",
      "validation accuracy:     0.5518\n",
      "Epoch 91, CIFAR-10 Batch 5:  loss:     0.4386\n",
      "validation accuracy:     0.5404\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss:     0.4402\n",
      "validation accuracy:     0.5418\n",
      "Epoch 92, CIFAR-10 Batch 2:  loss:     0.4628\n",
      "validation accuracy:     0.5500\n",
      "Epoch 92, CIFAR-10 Batch 3:  loss:     0.4649\n",
      "validation accuracy:     0.5352\n",
      "Epoch 92, CIFAR-10 Batch 4:  loss:     0.6197\n",
      "validation accuracy:     0.5520\n",
      "Epoch 92, CIFAR-10 Batch 5:  loss:     0.4189\n",
      "validation accuracy:     0.5500\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss:     0.4545\n",
      "validation accuracy:     0.5466\n",
      "Epoch 93, CIFAR-10 Batch 2:  loss:     0.4900\n",
      "validation accuracy:     0.5506\n",
      "Epoch 93, CIFAR-10 Batch 3:  loss:     0.4658\n",
      "validation accuracy:     0.5402\n",
      "Epoch 93, CIFAR-10 Batch 4:  loss:     0.5329\n",
      "validation accuracy:     0.5526\n",
      "Epoch 93, CIFAR-10 Batch 5:  loss:     0.4271\n",
      "validation accuracy:     0.5494\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss:     0.5143\n",
      "validation accuracy:     0.5410\n",
      "Epoch 94, CIFAR-10 Batch 2:  loss:     0.4910\n",
      "validation accuracy:     0.5542\n",
      "Epoch 94, CIFAR-10 Batch 3:  loss:     0.4697\n",
      "validation accuracy:     0.5516\n",
      "Epoch 94, CIFAR-10 Batch 4:  loss:     0.6262\n",
      "validation accuracy:     0.5486\n",
      "Epoch 94, CIFAR-10 Batch 5:  loss:     0.4176\n",
      "validation accuracy:     0.5552\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss:     0.4519\n",
      "validation accuracy:     0.5494\n",
      "Epoch 95, CIFAR-10 Batch 2:  loss:     0.4576\n",
      "validation accuracy:     0.5508\n",
      "Epoch 95, CIFAR-10 Batch 3:  loss:     0.4464\n",
      "validation accuracy:     0.5498\n",
      "Epoch 95, CIFAR-10 Batch 4:  loss:     0.5686\n",
      "validation accuracy:     0.5504\n",
      "Epoch 95, CIFAR-10 Batch 5:  loss:     0.4223\n",
      "validation accuracy:     0.5418\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss:     0.4882\n",
      "validation accuracy:     0.5460\n",
      "Epoch 96, CIFAR-10 Batch 2:  loss:     0.5094\n",
      "validation accuracy:     0.5580\n",
      "Epoch 96, CIFAR-10 Batch 3:  loss:     0.4460\n",
      "validation accuracy:     0.5500\n",
      "Epoch 96, CIFAR-10 Batch 4:  loss:     0.5932\n",
      "validation accuracy:     0.5442\n",
      "Epoch 96, CIFAR-10 Batch 5:  loss:     0.3984\n",
      "validation accuracy:     0.5394\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss:     0.4752\n",
      "validation accuracy:     0.5498\n",
      "Epoch 97, CIFAR-10 Batch 2:  loss:     0.4814\n",
      "validation accuracy:     0.5508\n",
      "Epoch 97, CIFAR-10 Batch 3:  loss:     0.4336\n",
      "validation accuracy:     0.5402\n",
      "Epoch 97, CIFAR-10 Batch 4:  loss:     0.5626\n",
      "validation accuracy:     0.5484\n",
      "Epoch 97, CIFAR-10 Batch 5:  loss:     0.4212\n",
      "validation accuracy:     0.5456\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss:     0.4707\n",
      "validation accuracy:     0.5490\n",
      "Epoch 98, CIFAR-10 Batch 2:  loss:     0.4347\n",
      "validation accuracy:     0.5418\n",
      "Epoch 98, CIFAR-10 Batch 3:  loss:     0.3850\n",
      "validation accuracy:     0.5576\n",
      "Epoch 98, CIFAR-10 Batch 4:  loss:     0.5638\n",
      "validation accuracy:     0.5444\n",
      "Epoch 98, CIFAR-10 Batch 5:  loss:     0.4232\n",
      "validation accuracy:     0.5348\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss:     0.5237\n",
      "validation accuracy:     0.5390\n",
      "Epoch 99, CIFAR-10 Batch 2:  loss:     0.4957\n",
      "validation accuracy:     0.5460\n",
      "Epoch 99, CIFAR-10 Batch 3:  loss:     0.3447\n",
      "validation accuracy:     0.5538\n",
      "Epoch 99, CIFAR-10 Batch 4:  loss:     0.5375\n",
      "validation accuracy:     0.5388\n",
      "Epoch 99, CIFAR-10 Batch 5:  loss:     0.4241\n",
      "validation accuracy:     0.5434\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss:     0.4506\n",
      "validation accuracy:     0.5448\n",
      "Epoch 100, CIFAR-10 Batch 2:  loss:     0.4789\n",
      "validation accuracy:     0.5476\n",
      "Epoch 100, CIFAR-10 Batch 3:  loss:     0.3653\n",
      "validation accuracy:     0.5548\n",
      "Epoch 100, CIFAR-10 Batch 4:  loss:     0.5917\n",
      "validation accuracy:     0.5520\n",
      "Epoch 100, CIFAR-10 Batch 5:  loss:     0.4100\n",
      "validation accuracy:     0.5484\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.5556329617834395\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb80854b588>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
